Spark assembly has been built with Hive, including Datanucleus jars on classpath
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/12/19 11:25:54 INFO SparkContext: Running Spark version 1.3.0
15/12/19 11:25:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/12/19 11:25:54 INFO SecurityManager: Changing view acls to: tad
15/12/19 11:25:54 INFO SecurityManager: Changing modify acls to: tad
15/12/19 11:25:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(tad); users with modify permissions: Set(tad)
15/12/19 11:25:55 INFO Slf4jLogger: Slf4jLogger started
15/12/19 11:25:55 INFO Remoting: Starting remoting
15/12/19 11:25:55 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.1.104:62055]
15/12/19 11:25:55 INFO Utils: Successfully started service 'sparkDriver' on port 62055.
15/12/19 11:25:55 INFO SparkEnv: Registering MapOutputTracker
15/12/19 11:25:55 INFO SparkEnv: Registering BlockManagerMaster
15/12/19 11:25:55 INFO DiskBlockManager: Created local directory at /var/folders/32/fhm6wnn17qs9dc20rqph_ftr0000gn/T/spark-0d078971-62ad-4b3b-a64a-9d87f1c922a9/blockmgr-57c6526b-8a92-40a0-b83c-0c8d5d71075a
15/12/19 11:25:55 INFO MemoryStore: MemoryStore started with capacity 265.1 MB
15/12/19 11:25:55 INFO HttpFileServer: HTTP File server directory is /var/folders/32/fhm6wnn17qs9dc20rqph_ftr0000gn/T/spark-07217273-7471-4ad3-a221-3eca3f0fa73b/httpd-a16e3747-9a34-443e-8eff-c9ff651f2d9a
15/12/19 11:25:55 INFO HttpServer: Starting HTTP Server
15/12/19 11:25:55 INFO Server: jetty-8.y.z-SNAPSHOT
15/12/19 11:25:55 INFO AbstractConnector: Started SocketConnector@0.0.0.0:62056
15/12/19 11:25:55 INFO Utils: Successfully started service 'HTTP file server' on port 62056.
15/12/19 11:25:55 INFO SparkEnv: Registering OutputCommitCoordinator
15/12/19 11:25:55 INFO Server: jetty-8.y.z-SNAPSHOT
15/12/19 11:25:55 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
15/12/19 11:25:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/12/19 11:25:55 INFO SparkUI: Started SparkUI at http://192.168.1.104:4040
15/12/19 11:25:55 INFO Utils: Copying /Users/tad/Dropbox/COMS_W4115/spawk/hello.py to /var/folders/32/fhm6wnn17qs9dc20rqph_ftr0000gn/T/spark-a95558ba-a143-46a1-93f1-fcaf999ba0f0/userFiles-2cd8c5de-7ce2-47ef-8bf2-c0e3ec94bc53/hello.py
15/12/19 11:25:55 INFO SparkContext: Added file file:/Users/tad/Dropbox/COMS_W4115/spawk/hello.py at file:/Users/tad/Dropbox/COMS_W4115/spawk/hello.py with timestamp 1450553155637
15/12/19 11:25:55 INFO Executor: Starting executor ID <driver> on host localhost
15/12/19 11:25:55 INFO AkkaUtils: Connecting to HeartbeatReceiver: akka.tcp://sparkDriver@192.168.1.104:62055/user/HeartbeatReceiver
15/12/19 11:25:55 INFO NettyBlockTransferService: Server created on 62057
15/12/19 11:25:55 INFO BlockManagerMaster: Trying to register BlockManager
15/12/19 11:25:55 INFO BlockManagerMasterActor: Registering block manager localhost:62057 with 265.1 MB RAM, BlockManagerId(<driver>, localhost, 62057)
15/12/19 11:25:55 INFO BlockManagerMaster: Registered BlockManager
15/12/19 11:25:56 INFO MemoryStore: ensureFreeSpace(211311) called with curMem=0, maxMem=278019440
15/12/19 11:25:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 206.4 KB, free 264.9 MB)
15/12/19 11:25:56 INFO MemoryStore: ensureFreeSpace(31262) called with curMem=211311, maxMem=278019440
15/12/19 11:25:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 30.5 KB, free 264.9 MB)
15/12/19 11:25:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:62057 (size: 30.5 KB, free: 265.1 MB)
15/12/19 11:25:56 INFO BlockManagerMaster: Updated info of block broadcast_0_piece0
15/12/19 11:25:56 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2
15/12/19 11:25:56 INFO FileInputFormat: Total input paths to process : 1
15/12/19 11:25:56 INFO SparkContext: Starting job: count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:21
15/12/19 11:25:56 INFO DAGScheduler: Got job 0 (count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:21) with 1 output partitions (allowLocal=false)
15/12/19 11:25:56 INFO DAGScheduler: Final stage: Stage 0(count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:21)
15/12/19 11:25:56 INFO DAGScheduler: Parents of final stage: List()
15/12/19 11:25:56 INFO DAGScheduler: Missing parents: List()
15/12/19 11:25:56 INFO DAGScheduler: Submitting Stage 0 (PythonRDD[3] at count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:21), which has no missing parents
15/12/19 11:25:56 INFO MemoryStore: ensureFreeSpace(6592) called with curMem=242573, maxMem=278019440
15/12/19 11:25:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.4 KB, free 264.9 MB)
15/12/19 11:25:56 INFO MemoryStore: ensureFreeSpace(4935) called with curMem=249165, maxMem=278019440
15/12/19 11:25:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.8 KB, free 264.9 MB)
15/12/19 11:25:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:62057 (size: 4.8 KB, free: 265.1 MB)
15/12/19 11:25:56 INFO BlockManagerMaster: Updated info of block broadcast_1_piece0
15/12/19 11:25:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:839
15/12/19 11:25:56 INFO DAGScheduler: Submitting 1 missing tasks from Stage 0 (PythonRDD[3] at count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:21)
15/12/19 11:25:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
15/12/19 11:25:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 1372 bytes)
15/12/19 11:25:56 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/12/19 11:25:56 INFO Executor: Fetching file:/Users/tad/Dropbox/COMS_W4115/spawk/hello.py with timestamp 1450553155637
15/12/19 11:25:56 INFO Utils: /Users/tad/Dropbox/COMS_W4115/spawk/hello.py has been previously copied to /var/folders/32/fhm6wnn17qs9dc20rqph_ftr0000gn/T/spark-a95558ba-a143-46a1-93f1-fcaf999ba0f0/userFiles-2cd8c5de-7ce2-47ef-8bf2-c0e3ec94bc53/hello.py
15/12/19 11:25:57 INFO CacheManager: Partition rdd_2_0 not found, computing it
15/12/19 11:25:57 INFO CacheManager: Partition rdd_1_0 not found, computing it
15/12/19 11:25:57 INFO HadoopRDD: Input split: file:/Users/tad/Dropbox/COMS_W4115/spawk/spawk.ml:0+1181
15/12/19 11:25:57 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
15/12/19 11:25:57 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
15/12/19 11:25:57 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
15/12/19 11:25:57 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
15/12/19 11:25:57 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
15/12/19 11:25:57 INFO MemoryStore: ensureFreeSpace(859) called with curMem=254100, maxMem=278019440
15/12/19 11:25:57 INFO MemoryStore: Block rdd_1_0 stored as bytes in memory (estimated size 859.0 B, free 264.9 MB)
15/12/19 11:25:57 INFO BlockManagerInfo: Added rdd_1_0 in memory on localhost:62057 (size: 859.0 B, free: 265.1 MB)
15/12/19 11:25:57 INFO BlockManagerMaster: Updated info of block rdd_1_0
15/12/19 11:25:57 INFO PythonRDD: Times: total = 89, boot = 3, init = 85, finish = 1
15/12/19 11:25:57 INFO MemoryStore: ensureFreeSpace(247) called with curMem=254959, maxMem=278019440
15/12/19 11:25:57 INFO MemoryStore: Block rdd_2_0 stored as bytes in memory (estimated size 247.0 B, free 264.9 MB)
15/12/19 11:25:57 INFO BlockManagerInfo: Added rdd_2_0 in memory on localhost:62057 (size: 247.0 B, free: 265.1 MB)
15/12/19 11:25:57 INFO BlockManagerMaster: Updated info of block rdd_2_0
15/12/19 11:25:57 INFO PythonRDD: Times: total = 1025, boot = 917, init = 108, finish = 0
15/12/19 11:25:57 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2494 bytes result sent to driver
15/12/19 11:25:57 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1131 ms on localhost (1/1)
15/12/19 11:25:57 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/12/19 11:25:57 INFO DAGScheduler: Stage 0 (count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:21) finished in 1.144 s
15/12/19 11:25:57 INFO DAGScheduler: Job 0 finished: count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:21, took 1.200392 s
15/12/19 11:25:57 INFO SparkContext: Starting job: count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:24
15/12/19 11:25:57 INFO DAGScheduler: Got job 1 (count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:24) with 1 output partitions (allowLocal=false)
15/12/19 11:25:57 INFO DAGScheduler: Final stage: Stage 1(count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:24)
15/12/19 11:25:57 INFO DAGScheduler: Parents of final stage: List()
15/12/19 11:25:57 INFO DAGScheduler: Missing parents: List()
15/12/19 11:25:57 INFO DAGScheduler: Submitting Stage 1 (PythonRDD[4] at count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:24), which has no missing parents
15/12/19 11:25:57 INFO MemoryStore: ensureFreeSpace(7016) called with curMem=255206, maxMem=278019440
15/12/19 11:25:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.9 KB, free 264.9 MB)
15/12/19 11:25:57 INFO MemoryStore: ensureFreeSpace(5315) called with curMem=262222, maxMem=278019440
15/12/19 11:25:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KB, free 264.9 MB)
15/12/19 11:25:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:62057 (size: 5.2 KB, free: 265.1 MB)
15/12/19 11:25:57 INFO BlockManagerMaster: Updated info of block broadcast_2_piece0
15/12/19 11:25:57 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:839
15/12/19 11:25:57 INFO DAGScheduler: Submitting 1 missing tasks from Stage 1 (PythonRDD[4] at count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:24)
15/12/19 11:25:57 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
15/12/19 11:25:57 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1372 bytes)
15/12/19 11:25:57 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
15/12/19 11:25:57 INFO BlockManager: Found block rdd_2_0 locally
15/12/19 11:25:57 INFO PythonRDD: Times: total = 5, boot = 0, init = 4, finish = 1
15/12/19 11:25:57 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1870 bytes result sent to driver
15/12/19 11:25:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 15 ms on localhost (1/1)
15/12/19 11:25:57 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/12/19 11:25:57 INFO DAGScheduler: Stage 1 (count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:24) finished in 0.016 s
15/12/19 11:25:57 INFO DAGScheduler: Job 1 finished: count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:24, took 0.032243 s
15/12/19 11:25:57 INFO SparkContext: Starting job: count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:25
15/12/19 11:25:57 INFO DAGScheduler: Got job 2 (count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:25) with 1 output partitions (allowLocal=false)
15/12/19 11:25:57 INFO DAGScheduler: Final stage: Stage 2(count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:25)
15/12/19 11:25:57 INFO DAGScheduler: Parents of final stage: List()
15/12/19 11:25:57 INFO DAGScheduler: Missing parents: List()
15/12/19 11:25:57 INFO DAGScheduler: Submitting Stage 2 (PythonRDD[5] at count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:25), which has no missing parents
15/12/19 11:25:57 INFO MemoryStore: ensureFreeSpace(7016) called with curMem=267537, maxMem=278019440
15/12/19 11:25:57 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.9 KB, free 264.9 MB)
15/12/19 11:25:57 INFO MemoryStore: ensureFreeSpace(5314) called with curMem=274553, maxMem=278019440
15/12/19 11:25:57 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.2 KB, free 264.9 MB)
15/12/19 11:25:57 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:62057 (size: 5.2 KB, free: 265.1 MB)
15/12/19 11:25:57 INFO BlockManagerMaster: Updated info of block broadcast_3_piece0
15/12/19 11:25:57 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:839
15/12/19 11:25:57 INFO DAGScheduler: Submitting 1 missing tasks from Stage 2 (PythonRDD[5] at count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:25)
15/12/19 11:25:57 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
15/12/19 11:25:57 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, PROCESS_LOCAL, 1372 bytes)
15/12/19 11:25:57 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
15/12/19 11:25:57 INFO BlockManager: Found block rdd_2_0 locally
15/12/19 11:25:57 INFO PythonRDD: Times: total = 2, boot = -17, init = 18, finish = 1
15/12/19 11:25:57 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1870 bytes result sent to driver
15/12/19 11:25:57 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 11 ms on localhost (1/1)
15/12/19 11:25:57 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/12/19 11:25:57 INFO DAGScheduler: Stage 2 (count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:25) finished in 0.011 s
15/12/19 11:25:57 INFO DAGScheduler: Job 2 finished: count at /Users/tad/Dropbox/COMS_W4115/spawk/hello.py:25, took 0.021296 s
